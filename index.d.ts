/* auto-generated by NAPI-RS */
/* eslint-disable */
/** Generate blurhash from image asynchronously */
export declare function blurhash(input: Buffer, componentsX?: number | undefined | null, componentsY?: number | undefined | null): Promise<BlurHashResult>

/** Raw hash result for blurhash */
export interface BlurHashResult {
  /** The blurhash string */
  hash: string
  /** Original width */
  width: number
  /** Original height */
  height: number
}

/** Generate blurhash from image synchronously */
export declare function blurhashSync(input: Buffer, componentsX?: number | undefined | null, componentsY?: number | undefined | null): BlurHashResult

/** Crop image asynchronously - zero-copy operation */
export declare function crop(input: Buffer, options: CropOptions): Promise<Buffer>

/** Crop gravity/anchor point */
export declare const enum CropGravity {
  /** Center of image (default) */
  Center = 'Center',
  /** Top center */
  North = 'North',
  /** Bottom center */
  South = 'South',
  /** Right center */
  East = 'East',
  /** Left center */
  West = 'West',
  /** Top left corner */
  NorthWest = 'NorthWest',
  /** Top right corner */
  NorthEast = 'NorthEast',
  /** Bottom left corner */
  SouthWest = 'SouthWest',
  /** Bottom right corner */
  SouthEast = 'SouthEast'
}

/** Crop options */
export interface CropOptions {
  /** X coordinate of crop origin (left edge) */
  x?: number
  /** Y coordinate of crop origin (top edge) */
  y?: number
  /** Width of crop region */
  width?: number
  /** Height of crop region */
  height?: number
  /**
   * Aspect ratio string (e.g., "16:9", "1:1", "4:3")
   * When set, crops to this ratio using gravity as anchor
   */
  aspectRatio?: string
  /** Gravity/anchor point for aspect ratio or dimension-based cropping */
  gravity?: CropGravity
}

/** Crop image synchronously - zero-copy operation */
export declare function cropSync(input: Buffer, options: CropOptions): Buffer

/** EXIF metadata options for writing */
export interface ExifOptions {
  /** Image description / caption / AI prompt */
  imageDescription?: string
  /** Artist / creator name */
  artist?: string
  /** Copyright notice */
  copyright?: string
  /** Software used to create the image */
  software?: string
  /** Date/time in EXIF format (YYYY:MM:DD HH:MM:SS) */
  dateTime?: string
  /** Original date/time in EXIF format */
  dateTimeOriginal?: string
  /** User comment (can contain JSON or other data) */
  userComment?: string
  /** Camera/device make */
  make?: string
  /** Camera/device model */
  model?: string
  /** Orientation (1-8) */
  orientation?: number
}

/** Image fit mode for resize */
export declare const enum FitMode {
  /** Resize to cover the target dimensions (may crop) */
  Cover = 'Cover',
  /** Resize to fit within target dimensions (may have padding) */
  Contain = 'Contain',
  /** Resize to exact dimensions (may distort) */
  Fill = 'Fill',
  /** Resize only if larger than target */
  Inside = 'Inside',
  /** Resize only if smaller than target */
  Outside = 'Outside'
}

/** Perceptual hash algorithm */
export declare const enum HashAlgorithm {
  /** Perceptual hash using DCT (best for most use cases) */
  PHash = 'PHash',
  /** Difference hash using gradients (fast, good for similar images) */
  DHash = 'DHash',
  /** Average hash (fastest, least robust) */
  AHash = 'AHash',
  /** Block hash (good balance of speed and accuracy) */
  BlockHash = 'BlockHash'
}

/** Hash size (dimensions of the hash grid) */
export declare const enum HashSize {
  /** 8x8 hash (64 bits) - fastest, good for most cases */
  Size8 = 'Size8',
  /** 16x16 hash (256 bits) - more accurate */
  Size16 = 'Size16',
  /** 32x32 hash (1024 bits) - highest accuracy */
  Size32 = 'Size32'
}

/** Image format enum */
export declare const enum ImageFormat {
  Jpeg = 'Jpeg',
  Png = 'Png',
  WebP = 'WebP',
  Gif = 'Gif',
  Bmp = 'Bmp',
  Ico = 'Ico',
  Tiff = 'Tiff',
  Heic = 'Heic',
  Avif = 'Avif'
}

/**
 * Generate perceptual hash from image asynchronously
 * Use for duplicate detection, content moderation, reverse image search
 */
export declare function imageHash(input: Buffer, algorithm?: HashAlgorithm | undefined | null, size?: HashSize | undefined | null): Promise<ImageHashResult>

/**
 * Calculate hamming distance between two perceptual hashes asynchronously
 * Returns 0 for identical images, higher values for more different images
 * Typical thresholds: <5 = very similar, <10 = similar, >10 = different
 */
export declare function imageHashDistance(hash1: string, hash2: string): Promise<number>

/**
 * Calculate hamming distance between two perceptual hashes synchronously
 * Returns 0 for identical images, higher values for more different images
 * Typical thresholds: <5 = very similar, <10 = similar, >10 = different
 */
export declare function imageHashDistanceSync(hash1: string, hash2: string): number

/** Perceptual hash result */
export interface ImageHashResult {
  /** The hash as a base64-encoded string */
  hash: string
  /** Original image width */
  width: number
  /** Original image height */
  height: number
  /** Hash size used (8, 16, or 32) */
  hashSize: number
  /** Algorithm used */
  algorithm: string
}

/**
 * Generate perceptual hash from image synchronously
 * Use for duplicate detection, content moderation, reverse image search
 */
export declare function imageHashSync(input: Buffer, algorithm?: HashAlgorithm | undefined | null, size?: HashSize | undefined | null): ImageHashResult

/** Image metadata (similar to sharp's output) */
export interface ImageMetadata {
  /** Image width in pixels */
  width: number
  /** Image height in pixels */
  height: number
  /** Detected format (jpeg, png, webp, gif, bmp, ico, tiff) */
  format: string
  /** File size in bytes (if available) */
  size?: number
  /** Color space (srgb, rgb, grayscale) */
  space: string
  /** Number of channels (1, 2, 3, or 4) */
  channels: number
  /** Bit depth per sample (uchar = 8-bit) */
  depth: string
  /** Whether the image has an alpha channel */
  hasAlpha: boolean
  /** Bits per sample */
  bitsPerSample: number
  /** Whether the image is progressive (JPEG) or interlaced (PNG) */
  isProgressive: boolean
  /** Whether the image uses palette/indexed colors (PNG/GIF) */
  isPalette: boolean
  /** Whether the image has an embedded ICC profile */
  hasProfile: boolean
  /** EXIF orientation value (1-8, if present) */
  orientation?: number
  /** Page/frame count for multi-page images (GIF, TIFF) */
  pages?: number
  /** Loop count for animated images */
  loopCount?: number
  /** Delay between frames in ms (for animated images) */
  delay?: Array<number>
  /** Background color (for GIF) */
  background?: Array<number>
  /** Compression type used */
  compression?: string
  /** Density/DPI info */
  density?: number
}

/** JPEG encode options */
export interface JpegOptions {
  /** Quality 1-100 (default: 80) */
  quality?: number
}

/** Get image metadata asynchronously */
export declare function metadata(input: Buffer): Promise<ImageMetadata>

/** Get image metadata synchronously */
export declare function metadataSync(input: Buffer): ImageMetadata

/** Output format options */
export interface OutputOptions {
  /** Output format */
  format: ImageFormat
  /** JPEG options (if format is JPEG) */
  jpeg?: JpegOptions
  /** PNG options (if format is PNG) */
  png?: PngOptions
  /** WebP options (if format is WebP) */
  webp?: WebPOptions
}

/** PNG encode options */
export interface PngOptions {
  /** Compression level 0-9 (default: 6) */
  compression?: number
}

/** Resize image asynchronously - uses scale-on-decode for JPEG optimization */
export declare function resize(input: Buffer, options: ResizeOptions): Promise<Buffer>

/** Resize filter/algorithm */
export declare const enum ResizeFilter {
  /** Nearest neighbor - fastest, lowest quality */
  Nearest = 'Nearest',
  /** Bilinear - fast, good quality */
  Bilinear = 'Bilinear',
  /** Catmull-Rom - balanced speed and quality */
  CatmullRom = 'CatmullRom',
  /** Mitchell - good for downscaling */
  Mitchell = 'Mitchell',
  /** Lanczos3 - highest quality, slower */
  Lanczos3 = 'Lanczos3'
}

/** Resize options */
export interface ResizeOptions {
  /** Target width (optional if height is provided) */
  width?: number
  /** Target height (optional if width is provided) */
  height?: number
  /** Resize filter/algorithm (default: Lanczos3) */
  filter?: ResizeFilter
  /** Fit mode (default: Cover) */
  fit?: FitMode
  /** Background color for padding [r, g, b, a] (default: transparent) */
  background?: Array<number>
}

/** Resize image synchronously - uses scale-on-decode for JPEG optimization */
export declare function resizeSync(input: Buffer, options: ResizeOptions): Buffer

/** Strip EXIF metadata from an image asynchronously */
export declare function stripExif(input: Buffer): Promise<Buffer>

/** Strip EXIF metadata from an image synchronously */
export declare function stripExifSync(input: Buffer): Buffer

/** Tensor data type */
export declare const enum TensorDtype {
  /** 32-bit floating point (default) */
  Float32 = 'Float32',
  /** 8-bit unsigned integer (raw pixels) */
  Uint8 = 'Uint8'
}

/** Tensor memory layout */
export declare const enum TensorLayout {
  /** Channel-Height-Width (PyTorch/ONNX default) */
  Chw = 'Chw',
  /** Height-Width-Channel (TensorFlow default) */
  Hwc = 'Hwc'
}

/** Normalization preset */
export declare const enum TensorNormalization {
  /** ImageNet normalization (mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]) */
  Imagenet = 'Imagenet',
  /** CLIP normalization (mean=[0.481,0.458,0.408], std=[0.269,0.261,0.276]) */
  Clip = 'Clip',
  /** Scale to [0, 1] range (divide by 255) */
  ZeroOne = 'ZeroOne',
  /** Scale to [-1, 1] range */
  NegOneOne = 'NegOneOne',
  /** No normalization (raw 0-255 values) */
  None = 'None'
}

/** Options for tensor conversion */
export interface TensorOptions {
  /** Output data type (default: Float32) */
  dtype?: TensorDtype
  /** Memory layout (default: CHW for PyTorch/ONNX) */
  layout?: TensorLayout
  /** Normalization preset (default: None) */
  normalization?: TensorNormalization
  /** Target width for resize before conversion */
  width?: number
  /** Target height for resize before conversion */
  height?: number
  /** Add batch dimension (default: false) */
  batch?: boolean
}

/** Tensor conversion result */
export interface TensorResult {
  /** Raw tensor data (Float32Array or Uint8Array bytes) */
  data: Array<number>
  /** Shape array (e.g., [3, 224, 224] or [1, 3, 224, 224]) */
  shape: Array<number>
  /** Data type used */
  dtype: TensorDtype
  /** Memory layout used */
  layout: TensorLayout
  /** Image width */
  width: number
  /** Image height */
  height: number
  /** Number of channels (always 3 for RGB) */
  channels: number
}

/**
 * Generate thumbhash from image asynchronously
 * ThumbHash produces smoother placeholders with alpha support and aspect ratio preservation
 * Note: Images are automatically resized to max 100x100 as required by ThumbHash algorithm
 * OPTIMIZED: Uses shrink-on-load to decode directly at reduced resolution (3x faster)
 */
export declare function thumbhash(input: Buffer): Promise<ThumbHashResult>

/** Decoded thumbhash result (RGBA pixels) */
export interface ThumbHashDecodeResult {
  /** RGBA pixel data */
  rgba: Array<number>
  /** Decoded width */
  width: number
  /** Decoded height */
  height: number
}

/** Raw hash result for thumbhash */
export interface ThumbHashResult {
  /** The thumbhash bytes (typically 25 bytes) */
  hash: Array<number>
  /** Original width */
  width: number
  /** Original height */
  height: number
  /** Whether image has alpha channel */
  hasAlpha: boolean
}

/**
 * Generate thumbhash from image synchronously
 * ThumbHash produces smoother placeholders with alpha support and aspect ratio preservation
 * Note: Images are automatically resized to max 100x100 as required by ThumbHash algorithm
 * OPTIMIZED: Uses shrink-on-load to decode directly at reduced resolution (3x faster)
 */
export declare function thumbhashSync(input: Buffer): ThumbHashResult

/** Decode thumbhash back to RGBA pixels asynchronously */
export declare function thumbhashToRgba(hash: Buffer): Promise<ThumbHashDecodeResult>

/** Decode thumbhash back to RGBA pixels synchronously */
export declare function thumbhashToRgbaSync(hash: Buffer): ThumbHashDecodeResult

/** Convert image to JPEG asynchronously */
export declare function toJpeg(input: Buffer, options?: JpegOptions | undefined | null): Promise<Buffer>

/** Convert image to JPEG synchronously */
export declare function toJpegSync(input: Buffer, options?: JpegOptions | undefined | null): Buffer

/** Convert image to PNG asynchronously */
export declare function toPng(input: Buffer, options?: PngOptions | undefined | null): Promise<Buffer>

/** Convert image to PNG synchronously */
export declare function toPngSync(input: Buffer, options?: PngOptions | undefined | null): Buffer

/**
 * Convert image to tensor format asynchronously
 * Optimized for ML preprocessing with SIMD and parallel processing
 */
export declare function toTensor(input: Buffer, options?: TensorOptions | undefined | null): Promise<TensorResult>

/**
 * Convert image to tensor format synchronously
 * Optimized for ML preprocessing with SIMD and parallel processing
 */
export declare function toTensorSync(input: Buffer, options?: TensorOptions | undefined | null): TensorResult

/** Convert image to WebP asynchronously */
export declare function toWebp(input: Buffer, options?: WebPOptions | undefined | null): Promise<Buffer>

/** Convert image to WebP synchronously */
export declare function toWebpSync(input: Buffer, options?: WebPOptions | undefined | null): Buffer

/** Transform image with multiple operations asynchronously */
export declare function transform(input: Buffer, options: TransformOptions): Promise<Buffer>

/** Transform options (all-in-one processing) */
export interface TransformOptions {
  /** Crop options (applied before resize) */
  crop?: CropOptions
  /** Resize options */
  resize?: ResizeOptions
  /** Output options */
  output?: OutputOptions
  /** Rotate degrees (90, 180, 270) */
  rotate?: number
  /** Flip horizontally */
  flipH?: boolean
  /** Flip vertically */
  flipV?: boolean
  /** Grayscale conversion */
  grayscale?: boolean
  /** Blur radius (0-100) - use integer, will be converted to float internally */
  blur?: number
  /** Sharpen amount (0-100) - use integer, will be converted to float internally */
  sharpen?: number
  /** Brightness adjustment (-100 to 100) */
  brightness?: number
  /** Contrast adjustment (-100 to 100) */
  contrast?: number
  /** EXIF metadata to write (for JPEG/WebP output) */
  exif?: ExifOptions
}

/** Transform image with multiple operations synchronously */
export declare function transformSync(input: Buffer, options: TransformOptions): Buffer

/** Get library version */
export declare function version(): string

/** WebP encode options */
export interface WebPOptions {
  /** Quality 1-100 for lossy, ignored for lossless (default: 80) */
  quality?: number
  /** Use lossless compression (default: false) */
  lossless?: boolean
}

/** Write EXIF metadata to a WebP image asynchronously */
export declare function writeExif(input: Buffer, options: ExifOptions): Promise<Buffer>

/** Write EXIF metadata to a WebP image synchronously */
export declare function writeExifSync(input: Buffer, options: ExifOptions): Buffer
